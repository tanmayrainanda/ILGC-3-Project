{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-08T18:45:46.326097Z","iopub.execute_input":"2022-09-08T18:45:46.327337Z","iopub.status.idle":"2022-09-08T18:45:46.453845Z","shell.execute_reply.started":"2022-09-08T18:45:46.327207Z","shell.execute_reply":"2022-09-08T18:45:46.452856Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#MobileNet\n\n\"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n\n\"This function returns a Keras image classification model, optionally loaded with weights pre-trained on ImageNet.\"\n\nhttps://keras.io/api/applications/mobilenet/","metadata":{}},{"cell_type":"markdown","source":"![](https://i.ytimg.com/vi/w8Qx40tHeEM/maxresdefault.jpg)","metadata":{}},{"cell_type":"markdown","source":"#All script by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n# Import Data Science Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.cm as cm\n\n# Tensorflow Libraries\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# System libraries\nfrom pathlib import Path\nimport os.path\n\n# Metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:46:06.020928Z","iopub.execute_input":"2022-09-08T18:46:06.021817Z","iopub.status.idle":"2022-09-08T18:46:11.282841Z","shell.execute_reply.started":"2022-09-08T18:46:06.021781Z","shell.execute_reply":"2022-09-08T18:46:11.281836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Helper functions","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n\n# Import series of helper functions for our notebook\nfrom helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-09-08T18:46:13.750801Z","iopub.execute_input":"2022-09-08T18:46:13.751400Z","iopub.status.idle":"2022-09-08T18:46:15.405735Z","shell.execute_reply.started":"2022-09-08T18:46:13.751365Z","shell.execute_reply":"2022-09-08T18:46:15.404567Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Load and Transform Data","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\nBATCH_SIZE = 32\nIMAGE_SIZE = (300, 300)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:46:50.717063Z","iopub.execute_input":"2022-09-08T18:46:50.717918Z","iopub.status.idle":"2022-09-08T18:46:50.723945Z","shell.execute_reply.started":"2022-09-08T18:46:50.717875Z","shell.execute_reply":"2022-09-08T18:46:50.721987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n# Walk through each directory\ndataset = \"../input/thermal-images-diseased-healthy-leaves-paddy\"\nwalk_through_dir(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:46:55.338360Z","iopub.execute_input":"2022-09-08T18:46:55.338724Z","iopub.status.idle":"2022-09-08T18:46:55.352219Z","shell.execute_reply.started":"2022-09-08T18:46:55.338692Z","shell.execute_reply":"2022-09-08T18:46:55.351118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\nimage_dir = Path(dataset)\n\n# Get filepaths and labels\nfilepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:02.784999Z","iopub.execute_input":"2022-09-08T18:47:02.786025Z","iopub.status.idle":"2022-09-08T18:47:02.836255Z","shell.execute_reply.started":"2022-09-08T18:47:02.785988Z","shell.execute_reply":"2022-09-08T18:47:02.835276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Placing data into a Dataframe","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\nimport PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\npath = Path(\"../input/thermal-images-diseased-healthy-leaves-paddy\").rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:11.077482Z","iopub.execute_input":"2022-09-08T18:47:11.077890Z","iopub.status.idle":"2022-09-08T18:47:13.590400Z","shell.execute_reply.started":"2022-09-08T18:47:11.077855Z","shell.execute_reply":"2022-09-08T18:47:13.589440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:18.476884Z","iopub.execute_input":"2022-09-08T18:47:18.477553Z","iopub.status.idle":"2022-09-08T18:47:18.498715Z","shell.execute_reply.started":"2022-09-08T18:47:18.477515Z","shell.execute_reply":"2022-09-08T18:47:18.497657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Visualizing images from the dataset","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n# Display 16 picture of the dataset with their labels\nrandom_index = np.random.randint(0, len(image_df), 16)\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n    ax.set_title(image_df.Label[random_index[i]])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:23.725060Z","iopub.execute_input":"2022-09-08T18:47:23.725913Z","iopub.status.idle":"2022-09-08T18:47:24.876465Z","shell.execute_reply.started":"2022-09-08T18:47:23.725879Z","shell.execute_reply":"2022-09-08T18:47:24.875597Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Separate in train and test data\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:30.920140Z","iopub.execute_input":"2022-09-08T18:47:30.920509Z","iopub.status.idle":"2022-09-08T18:47:30.929262Z","shell.execute_reply.started":"2022-09-08T18:47:30.920477Z","shell.execute_reply":"2022-09-08T18:47:30.928180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:35.858039Z","iopub.execute_input":"2022-09-08T18:47:35.858749Z","iopub.status.idle":"2022-09-08T18:47:35.864720Z","shell.execute_reply.started":"2022-09-08T18:47:35.858713Z","shell.execute_reply":"2022-09-08T18:47:35.863125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n# Split the data into three categories.\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:47:41.018779Z","iopub.execute_input":"2022-09-08T18:47:41.019174Z","iopub.status.idle":"2022-09-08T18:47:41.403768Z","shell.execute_reply.started":"2022-09-08T18:47:41.019140Z","shell.execute_reply":"2022-09-08T18:47:41.402722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Attention to number of classes, Number of Denses","metadata":{}},{"cell_type":"code","source":"# Resize Layer\nresize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(224,224),\n  layers.experimental.preprocessing.Rescaling(1./255),\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:48:31.522002Z","iopub.execute_input":"2022-09-08T18:48:31.522780Z","iopub.status.idle":"2022-09-08T18:48:31.533383Z","shell.execute_reply.started":"2022-09-08T18:48:31.522743Z","shell.execute_reply":"2022-09-08T18:48:31.532182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Training the model - MobileNetV2\n\nThe model images will be subjected to a pre-trained CNN model called MobileNetV2. Three callbacks will be utilized to monitor the training. These are: Model Checkpoint, Early Stopping, Tensorboard callback. The summary of the model hyperparameter is shown as follows:\n\nBatch size : 32\n\nEpochs : 100\n\nInput Shape : (224, 224, 3)\n\nOutput layer : 5\n\nBy VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook","metadata":{}},{"cell_type":"code","source":"# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV3Large(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:48:50.432389Z","iopub.execute_input":"2022-09-08T18:48:50.432796Z","iopub.status.idle":"2022-09-08T18:48:53.166060Z","shell.execute_reply.started":"2022-09-08T18:48:50.432759Z","shell.execute_reply":"2022-09-08T18:48:53.165096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create checkpoint callback\ncheckpoint_path = \"thermal_images_classification_model_checkpoint\"\ncheckpoint_callback = ModelCheckpoint(checkpoint_path,\n                                      save_weights_only=True,\n                                      monitor=\"val_accuracy\",\n                                      save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:49:02.372831Z","iopub.execute_input":"2022-09-08T18:49:02.373212Z","iopub.status.idle":"2022-09-08T18:49:02.378497Z","shell.execute_reply.started":"2022-09-08T18:49:02.373177Z","shell.execute_reply":"2022-09-08T18:49:02.377515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\nearly_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n                               patience = 6,\n                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:49:07.732485Z","iopub.execute_input":"2022-09-08T18:49:07.733389Z","iopub.status.idle":"2022-09-08T18:49:07.738465Z","shell.execute_reply.started":"2022-09-08T18:49:07.733353Z","shell.execute_reply":"2022-09-08T18:49:07.737285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Attention below: Original Dense was 5 We have 6 classes","metadata":{}},{"cell_type":"markdown","source":"#It started 15:49. Ended at 15:53","metadata":{}},{"cell_type":"code","source":"inputs = pretrained_model.input\nx = resize_and_rescale(inputs)\n\nx = Dense(256, activation='relu')(pretrained_model.output)\nx = Dropout(0.2)(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.2)(x)\n\n\noutputs = Dense(6, activation='softmax')(x)#Original Dense was 5 We have 6 classes\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer=Adam(0.00001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    steps_per_epoch=len(train_images),\n    validation_data=val_images,\n    validation_steps=len(val_images),\n    epochs=100,\n    callbacks=[\n        early_stopping,\n        create_tensorboard_callback(\"training_logs\", \n                                    \"thermal_images_classification\"),\n        checkpoint_callback,\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:49:12.866239Z","iopub.execute_input":"2022-09-08T18:49:12.866608Z","iopub.status.idle":"2022-09-08T18:52:45.909938Z","shell.execute_reply.started":"2022-09-08T18:49:12.866576Z","shell.execute_reply":"2022-09-08T18:52:45.908901Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Model Evaluation","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\nresults = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:53:11.307816Z","iopub.execute_input":"2022-09-08T18:53:11.308197Z","iopub.status.idle":"2022-09-08T18:53:11.930739Z","shell.execute_reply.started":"2022-09-08T18:53:11.308164Z","shell.execute_reply":"2022-09-08T18:53:11.929783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Visualizing loss curves","metadata":{}},{"cell_type":"code","source":"plot_loss_curves(history)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:53:36.495538Z","iopub.execute_input":"2022-09-08T18:53:36.495984Z","iopub.status.idle":"2022-09-08T18:53:36.985239Z","shell.execute_reply.started":"2022-09-08T18:53:36.495942Z","shell.execute_reply":"2022-09-08T18:53:36.984140Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Make Predictions","metadata":{}},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\n# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:53:44.644001Z","iopub.execute_input":"2022-09-08T18:53:44.644510Z","iopub.status.idle":"2022-09-08T18:53:46.602333Z","shell.execute_reply.started":"2022-09-08T18:53:44.644472Z","shell.execute_reply":"2022-09-08T18:53:46.601359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\n# Display 25 random pictures from the dataset with their labels\nrandom_index = np.random.randint(0, len(test_df) - 1, 15)\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n      color = \"green\"\n    else:\n      color = \"red\"\n    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\nplt.show()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:05.348831Z","iopub.execute_input":"2022-09-08T18:54:05.349210Z","iopub.status.idle":"2022-09-08T18:54:06.604575Z","shell.execute_reply.started":"2022-09-08T18:54:05.349177Z","shell.execute_reply":"2022-09-08T18:54:06.603772Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Plotting the Classification Reports and Confusion Matrix","metadata":{}},{"cell_type":"code","source":"y_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:14.558259Z","iopub.execute_input":"2022-09-08T18:54:14.558621Z","iopub.status.idle":"2022-09-08T18:54:14.573172Z","shell.execute_reply.started":"2022-09-08T18:54:14.558588Z","shell.execute_reply":"2022-09-08T18:54:14.572255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\nreport = classification_report(y_test, pred, output_dict=True)\ndf = pd.DataFrame(report).transpose()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:19.665267Z","iopub.execute_input":"2022-09-08T18:54:19.665624Z","iopub.status.idle":"2022-09-08T18:54:19.689335Z","shell.execute_reply.started":"2022-09-08T18:54:19.665592Z","shell.execute_reply":"2022-09-08T18:54:19.688233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(15, 7), text_size=10, norm=False, savefig=False): \n    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n    If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n    norm: normalize values or not (default=False).\n    savefig: save confusion matrix to file (default=False).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n    \"\"\"  \n  # Create the confustion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n    n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n    # Plot the figure and make it pretty\n    fig, ax = plt.subplots(figsize=figsize)\n    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n    fig.colorbar(cax)\n\n    # Are there a list of classes?\n    if classes:\n        labels = classes\n    else:\n        labels = np.arange(cm.shape[0])\n  \n    # Label the axes\n    ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n    # Make x-axis labels appear on bottom\n    ax.xaxis.set_label_position(\"bottom\")\n    ax.xaxis.tick_bottom()\n    ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n    plt.xticks(rotation=90, fontsize=text_size)\n    plt.yticks(fontsize=text_size)\n\n    # Set the threshold for different colors\n    threshold = (cm.max() + cm.min()) / 2.\n\n    # Plot the text on each cell\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if norm:\n            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i, j] > threshold else \"black\",\n                size=text_size)\n        else:\n            plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n\n  # Save the figure to the current working directory\n    if savefig:\n        fig.savefig(\"confusion_matrix.png\")","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:25.846808Z","iopub.execute_input":"2022-09-08T18:54:25.847201Z","iopub.status.idle":"2022-09-08T18:54:25.861349Z","shell.execute_reply.started":"2022-09-08T18:54:25.847167Z","shell.execute_reply":"2022-09-08T18:54:25.860348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_confusion_matrix(y_test, pred, list(labels.values()))","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:33.470506Z","iopub.execute_input":"2022-09-08T18:54:33.470892Z","iopub.status.idle":"2022-09-08T18:54:33.872474Z","shell.execute_reply.started":"2022-09-08T18:54:33.470860Z","shell.execute_reply":"2022-09-08T18:54:33.871504Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\ndef get_img_array(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size \"size\"\n    array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\ndef save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Load the original image\n    img = tf.keras.preprocessing.image.load_img(img_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n#     display(Image(cam_path))\n    \n    return cam_path\n    \n\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\ndecode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n\nlast_conv_layer_name = \"Conv_1\"\nimg_size = (224,224, 3)\n\n# Remove last layer's softmax\nmodel.layers[-1].activation = None","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:54:40.662582Z","iopub.execute_input":"2022-09-08T18:54:40.662946Z","iopub.status.idle":"2022-09-08T18:54:40.678628Z","shell.execute_reply.started":"2022-09-08T18:54:40.662913Z","shell.execute_reply":"2022-09-08T18:54:40.676386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by by VinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook\n\n\n# Display the part of the pictures used by the neural network to classify the pictures\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    img_path = test_df.Filepath.iloc[random_index[i]]\n    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n    cam_path = save_and_display_gradcam(img_path, heatmap)\n    ax.imshow(plt.imread(cam_path))\n    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-08T18:55:33.259519Z","iopub.execute_input":"2022-09-08T18:55:33.259879Z","iopub.status.idle":"2022-09-08T18:55:37.057763Z","shell.execute_reply.started":"2022-09-08T18:55:33.259848Z","shell.execute_reply":"2022-09-08T18:55:37.056830Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Coding by VinceVence","metadata":{}},{"cell_type":"markdown","source":"#Acknowledgements:\n\nVinceVence https://www.kaggle.com/code/vencerlanz09/plant-stress-classification-using-cnn-mobilenet/notebook","metadata":{}}]}